#!/usr/bin/env python3
"""
åˆ†æžå¤§èŠ‚ç‚¹æ¡ˆä¾‹çš„è¯¦ç»†ä¿¡æ¯
"""
import numpy as np
import os
from collections import Counter

def analyze_large_cases():
    """åˆ†æžå¤§èŠ‚ç‚¹æ¡ˆä¾‹"""
    npz_dir = "/home/lihe/classify/lungmap/data/processed"
    large_cases = ["4000010084_processed.npz", "4000010082_processed.npz", "3000020023_processed.npz"]
    
    print("ðŸ” åˆ†æžå¤§èŠ‚ç‚¹æ¡ˆä¾‹")
    print("=" * 60)
    
    for filename in large_cases:
        filepath = os.path.join(npz_dir, filename)
        if not os.path.exists(filepath):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            continue
            
        print(f"\nðŸ“‹ æ¡ˆä¾‹: {filename}")
        print("-" * 40)
        
        try:
            data = np.load(filepath, allow_pickle=True)
            
            case_id = data['case_id'].item()
            node_features = data['node_features']
            node_positions = data['node_positions']
            edge_index = data['edge_index']
            image_cubes = data['image_cubes']
            node_classes = data['node_classes']
            vessel_ranges = data['vessel_node_ranges'].item()
            node_to_vessel = data['node_to_vessel']
            
            print(f"ðŸ†” ç—…ä¾‹ID: {case_id}")
            print(f"ðŸ“Š èŠ‚ç‚¹æ•°é‡: {len(node_features)}")
            print(f"ðŸ”— è¾¹æ•°é‡: {edge_index.shape[1]}")
            print(f"ðŸ©¸ è¡€ç®¡æ•°é‡: {len(vessel_ranges)}")
            
            # åˆ†æžè¡€ç®¡åˆ†å¸ƒ
            print(f"\nðŸ©¸ è¡€ç®¡è¯¦ç»†åˆ†å¸ƒ:")
            total_vessel_nodes = 0
            for vessel_name, (start, end) in vessel_ranges.items():
                node_count = end - start + 1
                total_vessel_nodes += node_count
                vessel_classes = node_classes[start:end+1]
                unique_classes = len(set(vessel_classes))
                avg_class = np.mean(vessel_classes)
                print(f"  {vessel_name:12s}: èŠ‚ç‚¹ {start:3d}-{end:3d} ({node_count:3d}ä¸ª) - ç±»åˆ«: {unique_classes} (å¹³å‡: {avg_class:.1f})")
            
            print(f"  æ€»è¡€ç®¡èŠ‚ç‚¹æ•°: {total_vessel_nodes}")
            
            # åˆ†æžèŠ‚ç‚¹ç±»åˆ«åˆ†å¸ƒ
            print(f"\nðŸŽ¯ èŠ‚ç‚¹ç±»åˆ«åˆ†å¸ƒ:")
            class_counts = Counter(node_classes)
            for class_id in sorted(class_counts.keys()):
                count = class_counts[class_id]
                percentage = count / len(node_classes) * 100
                print(f"  ç±»åˆ« {class_id:2d}: {count:3d} ä¸ªèŠ‚ç‚¹ ({percentage:5.1f}%)")
            
            # åˆ†æžç©ºé—´åˆ†å¸ƒ
            print(f"\nðŸ“ ç©ºé—´åˆ†å¸ƒ:")
            print(f"  X èŒƒå›´: {node_positions[:, 0].min():.1f} ~ {node_positions[:, 0].max():.1f} (è·¨åº¦: {node_positions[:, 0].max() - node_positions[:, 0].min():.1f})")
            print(f"  Y èŒƒå›´: {node_positions[:, 1].min():.1f} ~ {node_positions[:, 1].max():.1f} (è·¨åº¦: {node_positions[:, 1].max() - node_positions[:, 1].min():.1f})")
            print(f"  Z èŒƒå›´: {node_positions[:, 2].min():.1f} ~ {node_positions[:, 2].max():.1f} (è·¨åº¦: {node_positions[:, 2].max() - node_positions[:, 2].min():.1f})")
            
            # åˆ†æžç‰¹å¾ç»Ÿè®¡
            print(f"\nðŸ“ˆ ç‰¹å¾ç»Ÿè®¡:")
            print(f"  ç‰¹å¾å‡å€¼èŒƒå›´: {node_features.mean(axis=0).min():.3f} ~ {node_features.mean(axis=0).max():.3f}")
            print(f"  ç‰¹å¾æ ‡å‡†å·®èŒƒå›´: {node_features.std(axis=0).min():.3f} ~ {node_features.std(axis=0).max():.3f}")
            
            # åˆ†æžå›¾åƒæ•°æ®
            print(f"\nðŸ–¼ï¸  å›¾åƒå—åˆ†æž:")
            print(f"  å½¢çŠ¶: {image_cubes.shape}")
            print(f"  å¼ºåº¦èŒƒå›´: {image_cubes.min():.3f} ~ {image_cubes.max():.3f}")
            print(f"  æ•°æ®å¤§å°: {image_cubes.nbytes / 1024 / 1024:.1f} MB")
            
            # æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(filepath) / 1024 / 1024
            print(f"\nðŸ’¾ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„è¡€ç®¡ç±»åž‹
            vessel_types = list(vessel_ranges.keys())
            print(f"\nðŸ” è¡€ç®¡ç±»åž‹: {vessel_types}")
            
            # æ£€æŸ¥èŠ‚ç‚¹å¯†åº¦
            if len(vessel_ranges) > 0:
                avg_nodes_per_vessel = len(node_features) / len(vessel_ranges)
                print(f"ðŸ“Š å¹³å‡æ¯ä¸ªè¡€ç®¡èŠ‚ç‚¹æ•°: {avg_nodes_per_vessel:.1f}")
            
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            continue
        
        print("=" * 60)

def compare_with_normal_cases():
    """ä¸Žæ­£å¸¸æ¡ˆä¾‹å¯¹æ¯”"""
    print(f"\nðŸ“Š ä¸Žæ­£å¸¸æ¡ˆä¾‹å¯¹æ¯”:")
    print("=" * 60)
    
    npz_dir = "/home/lihe/classify/lungmap/data/processed"
    all_files = [f for f in os.listdir(npz_dir) if f.endswith('.npz')]
    
    node_counts = []
    vessel_counts = []
    
    for filename in all_files:
        filepath = os.path.join(npz_dir, filename)
        try:
            data = np.load(filepath, allow_pickle=True)
            node_count = len(data['node_features'])
            vessel_count = len(data['vessel_node_ranges'].item())
            
            node_counts.append((filename, node_count))
            vessel_counts.append((filename, vessel_count))
            
        except Exception as e:
            continue
    
    # æŒ‰èŠ‚ç‚¹æ•°æŽ’åº
    node_counts.sort(key=lambda x: x[1], reverse=True)
    
    print("ðŸ” èŠ‚ç‚¹æ•°æœ€å¤šçš„10ä¸ªæ¡ˆä¾‹:")
    for i, (filename, count) in enumerate(node_counts[:10]):
        marker = "ðŸ”¥" if count > 100 else "ðŸ“Š"
        print(f"  {i+1:2d}. {marker} {filename:25s}: {count:3d} èŠ‚ç‚¹")
    
    print(f"\nðŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    all_node_counts = [count for _, count in node_counts]
    print(f"  æœ€å°èŠ‚ç‚¹æ•°: {min(all_node_counts)}")
    print(f"  æœ€å¤§èŠ‚ç‚¹æ•°: {max(all_node_counts)}")
    print(f"  å¹³å‡èŠ‚ç‚¹æ•°: {np.mean(all_node_counts):.1f}")
    print(f"  ä¸­ä½æ•°èŠ‚ç‚¹æ•°: {np.median(all_node_counts):.1f}")
    print(f"  è¶…è¿‡100èŠ‚ç‚¹çš„æ¡ˆä¾‹: {sum(1 for count in all_node_counts if count > 100)} / {len(all_node_counts)}")

if __name__ == "__main__":
    analyze_large_cases()
    compare_with_normal_cases()
