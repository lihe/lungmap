#!/usr/bin/env python3
"""
è¯¦ç»†åˆ†æé‡å¤åæ ‡å’Œç‰¹å¾çš„bug
"""
import numpy as np
import os

def analyze_coordinate_duplication():
    """åˆ†æåæ ‡é‡å¤çš„è¯¦ç»†æƒ…å†µ"""
    npz_dir = "/home/lihe/classify/lungmap/data/processed"
    problematic_cases = ["4000010084_processed.npz", "4000010082_processed.npz", "3000020023_processed.npz"]
    
    print("ğŸ” è¯¦ç»†åˆ†æåæ ‡é‡å¤Bug")
    print("=" * 70)
    
    for filename in problematic_cases:
        filepath = os.path.join(npz_dir, filename)
        if not os.path.exists(filepath):
            continue
            
        print(f"\nğŸ“‹ åˆ†æ: {filename}")
        print("-" * 50)
        
        data = np.load(filepath, allow_pickle=True)
        
        case_id = data['case_id'].item()
        node_positions = data['node_positions']  
        vessel_ranges = data['vessel_node_ranges'].item()
        node_features = data['node_features']
        
        print(f"æ€»èŠ‚ç‚¹æ•°: {len(node_positions)}")
        
        # æ£€æŸ¥å…¨å±€åæ ‡é‡å¤
        unique_positions = np.unique(node_positions, axis=0)
        total_duplicates = len(node_positions) - len(unique_positions)
        print(f"é‡å¤åæ ‡ç‚¹: {total_duplicates} / {len(node_positions)} ({total_duplicates/len(node_positions)*100:.1f}%)")
        
        # åˆ†è¡€ç®¡æ£€æŸ¥
        for vessel_name, (start, end) in vessel_ranges.items():
            vessel_positions = node_positions[start:end+1]
            vessel_features = node_features[start:end+1]
            
            print(f"\n  {vessel_name} è¡€ç®¡:")
            print(f"    èŠ‚ç‚¹èŒƒå›´: {start}-{end} ({end-start+1}ä¸ª)")
            
            # æ£€æŸ¥åæ ‡é‡å¤
            unique_vessel_pos = np.unique(vessel_positions, axis=0)
            vessel_duplicates = len(vessel_positions) - len(unique_vessel_pos)
            if vessel_duplicates > 0:
                print(f"    ğŸ”´ åæ ‡é‡å¤: {vessel_duplicates} ä¸ª")
                
                # æ‰¾å‡ºé‡å¤çš„åæ ‡
                from collections import Counter
                pos_strings = [f"{p[0]:.1f},{p[1]:.1f},{p[2]:.1f}" for p in vessel_positions]
                pos_counts = Counter(pos_strings)
                duplicated_coords = {coord: count for coord, count in pos_counts.items() if count > 1}
                
                for coord, count in duplicated_coords.items():
                    print(f"      é‡å¤åæ ‡ {coord}: å‡ºç° {count} æ¬¡")
            
            # æ£€æŸ¥ç‰¹å¾é‡å¤
            unique_vessel_features = np.unique(vessel_features, axis=0)
            feature_duplicates = len(vessel_features) - len(unique_vessel_features)
            if feature_duplicates > 0:
                print(f"    ğŸ”´ ç‰¹å¾é‡å¤: {feature_duplicates} ä¸ª")
            
            # æ£€æŸ¥åæ ‡çš„åˆ†å¸ƒæ¨¡å¼
            x_coords = vessel_positions[:, 0]
            y_coords = vessel_positions[:, 1] 
            z_coords = vessel_positions[:, 2]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è§„å¾‹çš„é—´éš”
            x_sorted = np.sort(x_coords)
            x_diffs = np.diff(x_sorted)
            x_diffs = x_diffs[x_diffs > 0.001]  # å¿½ç•¥æå°çš„å·®å¼‚
            
            if len(x_diffs) > 0:
                x_diff_std = np.std(x_diffs)
                x_diff_mean = np.mean(x_diffs)
                
                if x_diff_std < 0.1 and len(x_diffs) > 5:
                    print(f"    âš ï¸  Xåæ ‡é—´éš”è¿‡äºè§„å¾‹: å¹³å‡é—´éš” {x_diff_mean:.2f} Â± {x_diff_std:.3f}")
            
            # æ£€æŸ¥åæ ‡æ˜¯å¦å®Œå…¨ç›¸åŒ
            if len(unique_vessel_pos) == 1:
                print(f"    ğŸ”´ ä¸¥é‡BUG: æ‰€æœ‰åæ ‡ç‚¹å®Œå…¨ç›¸åŒ {unique_vessel_pos[0]}")
            
            # æ£€æŸ¥ç‰¹å¾çš„åˆ†å¸ƒ
            feature_means = np.mean(vessel_features, axis=0)
            feature_stds = np.std(vessel_features, axis=0)
            
            zero_std_features = np.sum(feature_stds < 1e-6)
            if zero_std_features > 0:
                print(f"    ğŸ”´ ç‰¹å¾BUG: {zero_std_features} ä¸ªç‰¹å¾ç»´åº¦æ ‡å‡†å·®ä¸º0 (ç‰¹å¾å®Œå…¨ç›¸åŒ)")
            
            low_variance_features = np.sum(feature_stds < 0.01)
            if low_variance_features > 10:
                print(f"    âš ï¸  {low_variance_features} ä¸ªç‰¹å¾ç»´åº¦æ–¹å·®å¾ˆå°")

def analyze_preprocessing_pattern():
    """åˆ†æé¢„å¤„ç†çš„å…·ä½“æ¨¡å¼"""
    print(f"\nğŸ”¬ åˆ†æé¢„å¤„ç†æ¨¡å¼")
    print("=" * 70)
    
    npz_dir = "/home/lihe/classify/lungmap/data/processed"
    problematic_cases = ["4000010084_processed.npz", "4000010082_processed.npz", "3000020023_processed.npz"]
    
    for filename in problematic_cases:
        filepath = os.path.join(npz_dir, filename)
        if not os.path.exists(filepath):
            continue
            
        print(f"\nğŸ“‹ é¢„å¤„ç†æ¨¡å¼åˆ†æ: {filename}")
        print("-" * 50)
        
        data = np.load(filepath, allow_pickle=True)
        
        vessel_ranges = data['vessel_node_ranges'].item()
        node_positions = data['node_positions']
        
        # æ£€æŸ¥èŠ‚ç‚¹æ•°æ¨¡å¼
        vessel_node_counts = {}
        for vessel_name, (start, end) in vessel_ranges.items():
            count = end - start + 1
            vessel_node_counts[vessel_name] = count
        
        all_counts = list(vessel_node_counts.values())
        if len(set(all_counts)) == 1:
            print(f"ğŸ”´ æ¨¡å¼å¼‚å¸¸: æ‰€æœ‰è¡€ç®¡éƒ½æœ‰ {all_counts[0]} ä¸ªèŠ‚ç‚¹")
            
            # åˆ†æè¿™ä¸ªæ•°å­—æ˜¯å¦æœ‰ç‰¹æ®Šå«ä¹‰
            target_count = all_counts[0]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç®€å•çš„ç­‰åˆ†
            total_unique_positions = len(np.unique(node_positions, axis=0))
            if total_unique_positions * len(vessel_ranges) == len(node_positions):
                print(f"  ğŸ” å¯èƒ½çš„åŸå› : å°† {total_unique_positions} ä¸ªå”¯ä¸€ä½ç½®å¤åˆ¶åˆ° {len(vessel_ranges)} ä¸ªè¡€ç®¡")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å›ºå®šé‡‡æ ·æ•°
            common_sampling_nums = [50, 64, 90, 99, 100, 128, 256]
            if target_count in common_sampling_nums:
                print(f"  ğŸ” å¯èƒ½çš„åŸå› : å›ºå®šé‡‡æ ·åˆ° {target_count} ä¸ªç‚¹")
            
            # æ£€æŸ¥æ€»æ•°æ˜¯å¦æœ‰è§„å¾‹
            total_nodes = len(node_positions)
            if total_nodes % len(vessel_ranges) == 0:
                nodes_per_vessel = total_nodes // len(vessel_ranges)
                print(f"  ğŸ” å‘ç°è§„å¾‹: æ€»èŠ‚ç‚¹æ•° {total_nodes} è¢«å¹³å‡åˆ†é…ç»™ {len(vessel_ranges)} ä¸ªè¡€ç®¡")
        
        # æ£€æŸ¥åæ ‡èŒƒå›´çš„ç›¸åŒæ€§
        print(f"\n  åæ ‡èŒƒå›´åˆ†æ:")
        vessel_ranges_coords = {}
        for vessel_name, (start, end) in vessel_ranges.items():
            vessel_pos = node_positions[start:end+1]
            x_range = vessel_pos[:, 0].max() - vessel_pos[:, 0].min()
            y_range = vessel_pos[:, 1].max() - vessel_pos[:, 1].min()
            z_range = vessel_pos[:, 2].max() - vessel_pos[:, 2].min()
            vessel_ranges_coords[vessel_name] = (x_range, y_range, z_range)
            print(f"    {vessel_name}: X={x_range:.1f}, Y={y_range:.1f}, Z={z_range:.1f}")
        
        # æ£€æŸ¥æ‰€æœ‰è¡€ç®¡çš„åæ ‡èŒƒå›´æ˜¯å¦ç›¸åŒ
        all_ranges = list(vessel_ranges_coords.values())
        if len(set([(round(r[0], 1), round(r[1], 1), round(r[2], 1)) for r in all_ranges])) == 1:
            print(f"  ğŸ”´ BUG: æ‰€æœ‰è¡€ç®¡çš„åæ ‡èŒƒå›´å®Œå…¨ç›¸åŒ!")
            print(f"       è¿™è¡¨æ˜æ‰€æœ‰è¡€ç®¡å¯èƒ½å…±äº«åŒä¸€ç»„åæ ‡ç‚¹")

def suggest_fixes():
    """å»ºè®®ä¿®å¤æ–¹æ¡ˆ"""
    print(f"\nğŸ’¡ Bugä¿®å¤å»ºè®®")
    print("=" * 70)
    
    print("æ ¹æ®åˆ†æç»“æœï¼Œå‘ç°çš„ä¸»è¦Bugç±»å‹:")
    print()
    print("1. ğŸ”´ æ‰€æœ‰è¡€ç®¡èŠ‚ç‚¹æ•°å®Œå…¨ç›¸åŒ")
    print("   - åŸå› : é¢„å¤„ç†ç®—æ³•å¯èƒ½é”™è¯¯åœ°å¯¹æ‰€æœ‰è¡€ç®¡åº”ç”¨äº†ç›¸åŒçš„é‡‡æ ·ç­–ç•¥")
    print("   - å½±å“: è¿åäº†è¡€ç®¡ç³»ç»Ÿçš„è‡ªç„¶å±‚æ¬¡ç»“æ„")
    print("   - ä¿®å¤: æ ¹æ®è¡€ç®¡ç±»å‹å’Œå¤æ‚åº¦è‡ªé€‚åº”é‡‡æ ·")
    print()
    print("2. ğŸ”´ å¤§é‡é‡å¤åæ ‡ç‚¹") 
    print("   - åŸå› : é¢„å¤„ç†è¿‡ç¨‹ä¸­å¯èƒ½å°†ç›¸åŒçš„ç‚¹é›†å¤åˆ¶ç»™äº†å¤šä¸ªè¡€ç®¡")
    print("   - å½±å“: å›¾ç»“æ„ä¸æ­£ç¡®ï¼Œè®­ç»ƒæ—¶ä¼šäº§ç”Ÿé”™è¯¯çš„å‡ ä½•å…³ç³»")
    print("   - ä¿®å¤: ç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹åªå±äºä¸€ä¸ªè¡€ç®¡ï¼Œé¿å…é‡å¤")
    print()
    print("3. ğŸ”´ æ‰€æœ‰è¡€ç®¡åæ ‡èŒƒå›´ç›¸åŒ")
    print("   - åŸå› : å¯èƒ½æ‰€æœ‰è¡€ç®¡å…±äº«åŒä¸€ä¸ªè¾¹ç•Œæ¡†å†…çš„é‡‡æ ·ç‚¹")
    print("   - å½±å“: å¤±å»äº†è¡€ç®¡é—´çš„ç©ºé—´åŒºåˆ†åº¦")
    print("   - ä¿®å¤: ä¸ºæ¯ä¸ªè¡€ç®¡ç‹¬ç«‹æå–å…¶ç‰¹å®šåŒºåŸŸçš„ç‚¹")
    print()
    print("å»ºè®®çš„å¤„ç†ç­–ç•¥:")
    print("âœ… çŸ­æœŸ: è¿‡æ»¤æ‰è¿™3ä¸ªå¼‚å¸¸æ¡ˆä¾‹ï¼Œç”¨æ­£å¸¸çš„21ä¸ªæ¡ˆä¾‹è¿›è¡Œè®­ç»ƒ")
    print("âœ… é•¿æœŸ: é‡æ–°è®¾è®¡é¢„å¤„ç†ç®—æ³•ï¼Œç¡®ä¿è¡€ç®¡é—´çš„ç‹¬ç«‹æ€§å’Œå±‚æ¬¡æ€§")
    print("âœ… éªŒè¯: å¯¹æ‰€æœ‰æ¡ˆä¾‹è¿è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼Œç¡®ä¿æ•°æ®è´¨é‡")

if __name__ == "__main__":
    analyze_coordinate_duplication()
    analyze_preprocessing_pattern()
    suggest_fixes()
