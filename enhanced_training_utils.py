#!/usr/bin/env python3
"""
CPR-TaG-Net å¢å¼ºè®­ç»ƒå·¥å…· - é›†æˆå›¾å½¢è¡¥å…¨ã€å¯è§†åŒ–ç­‰é«˜çº§åŠŸèƒ½
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from collections import defaultdict
import os
from pathlib import Path

class EnhancedTrainingUtils:
    """é›†æˆå›¾å½¢è¡¥å…¨ã€å¯è§†åŒ–ç­‰é«˜çº§åŠŸèƒ½çš„è®­ç»ƒå·¥å…·"""
    
    def __init__(self, vessel_classes=None, save_dir="outputs/visualizations"):
        """
        åˆå§‹åŒ–å¢å¼ºè®­ç»ƒå·¥å…·
        Args:
            vessel_classes: è¡€ç®¡ç±»åˆ«å­—å…¸ï¼Œæ ¼å¼ {"ç±»åˆ«å": ç±»åˆ«ID}
            save_dir: å¯è§†åŒ–ç»“æœä¿å­˜ç›®å½•
        """
        self.vessel_classes = vessel_classes or self._get_default_vessel_classes()
        self.class_names = list(self.vessel_classes.keys())
        self.num_classes = len(self.class_names)
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ§  å¢å¼ºè®­ç»ƒå·¥å…·åˆå§‹åŒ–å®Œæˆ")
        print(f"   è¡€ç®¡ç±»åˆ«æ•°: {self.num_classes}")
        print(f"   å¯è§†åŒ–ä¿å­˜ç›®å½•: {self.save_dir}")
        
    def _get_default_vessel_classes(self):
        """è·å–é»˜è®¤çš„15ç±»è¡€ç®¡åˆ†ç±»"""
        return {
            'MPA': 0, 'LPA': 1, 'RPA': 2,
            'Lupper': 3, 'Rupper': 4,
            'L1+2': 5, 'R1+2': 6,
            'L1+3': 7, 'R1+3': 8,
            'Linternal': 9, 'Rinternal': 10,
            'Lmedium': 11, 'Rmedium': 12,
            'Ldown': 13, 'RDown': 14
        }
        
    def complete_graph(self, centerline_pos, predicted_labels, distance_threshold=5.0):
        """
        ğŸ§  å›¾å½¢è¡¥å…¨ï¼šåŸºäºè¡€ç®¡è¿ç»­æ€§çº¦æŸä¼˜åŒ–åˆ†ç±»ç»“æœ
        
        Args:
            centerline_pos: ä¸­å¿ƒçº¿ä½ç½® [N, 3]
            predicted_labels: é¢„æµ‹æ ‡ç­¾ [N]
            distance_threshold: è·ç¦»é˜ˆå€¼
            
        Returns:
            refined_labels: ä¼˜åŒ–åçš„æ ‡ç­¾ [N]
            edge_index: æ–°å»ºç«‹çš„è¾¹è¿æ¥ [2, E]
        """
        if len(centerline_pos) == 0:
            return predicted_labels, torch.empty((2, 0), dtype=torch.long)
            
        print(f"ğŸ”§ æ‰§è¡Œå›¾å½¢è¡¥å…¨: {len(centerline_pos)} ä¸ªèŠ‚ç‚¹")
        
        # ç¡®ä¿è¾“å…¥æ˜¯tensoræ ¼å¼
        if not isinstance(centerline_pos, torch.Tensor):
            centerline_pos = torch.tensor(centerline_pos, dtype=torch.float32)
        if not isinstance(predicted_labels, torch.Tensor):
            predicted_labels = torch.tensor(predicted_labels, dtype=torch.long)
            
        # è®¡ç®—èŠ‚ç‚¹é—´è·ç¦»çŸ©é˜µ
        distances = torch.cdist(centerline_pos, centerline_pos)  # [N, N]
        
        # æ‰¾åˆ°ç›¸è¿‘çš„èŠ‚ç‚¹å¯¹
        close_pairs = torch.where((distances < distance_threshold) & (distances > 0))
        
        # åŸºäºæ ‡ç­¾ä¸€è‡´æ€§å’Œè§£å‰–å­¦è§„åˆ™å»ºç«‹è¿æ¥
        refined_edges = []
        refined_labels = predicted_labels.clone()
        connection_count = 0
        label_update_count = 0
        
        for i, j in zip(close_pairs[0], close_pairs[1]):
            if i < j:  # é¿å…é‡å¤è¾¹
                label_i, label_j = predicted_labels[i], predicted_labels[j]
                
                # å¦‚æœæ ‡ç­¾ç›¸åŒæˆ–ç›¸é‚»ï¼ˆåŸºäºè¡€ç®¡è§£å‰–å­¦ï¼‰ï¼Œå»ºç«‹è¿æ¥
                if self._should_connect(label_i, label_j):
                    refined_edges.append([i.item(), j.item()])
                    connection_count += 1
                    
                    # æ ‡ç­¾å¹³æ»‘ï¼šåŸºäºé‚»åŸŸä¸€è‡´æ€§æ›´æ–°æ ‡ç­¾
                    if self._should_update_label(i, j, distances, predicted_labels):
                        refined_labels[i] = predicted_labels[j]
                        label_update_count += 1
        
        print(f"   âœ… å»ºç«‹è¿æ¥: {connection_count} æ¡è¾¹")
        print(f"   âœ… æ ‡ç­¾ä¼˜åŒ–: {label_update_count} ä¸ªèŠ‚ç‚¹")
        
        if len(refined_edges) == 0:
            return refined_labels, torch.empty((2, 0), dtype=torch.long)
        
        edge_index = torch.tensor(refined_edges, dtype=torch.long).T  # [2, E]
        return refined_labels, edge_index
    
    def _should_connect(self, label_i, label_j):
        """åˆ¤æ–­ä¸¤ä¸ªæ ‡ç­¾çš„è¡€ç®¡æ®µæ˜¯å¦åº”è¯¥è¿æ¥"""
        # è¡€ç®¡è§£å‰–è¿æ¥è§„åˆ™ - åŸºäº15ç±»è‚ºè¡€ç®¡æ ‘ç»“æ„
        anatomical_connections = {
            0: [1, 2],      # MPA -> LPA, RPA
            1: [3, 5, 7, 9, 11, 13],    # LPA -> Lupper, L1+2, L1+3, Linternal, Lmedium, Ldown
            2: [4, 6, 8, 10, 12, 14],   # RPA -> Rupper, R1+2, R1+3, Rinternal, Rmedium, RDown
        }
        
        # ç›¸åŒæ ‡ç­¾å¯ä»¥è¿æ¥
        if label_i == label_j:
            return True
            
        # æ£€æŸ¥è§£å‰–è¿æ¥å…³ç³»ï¼ˆåŒå‘ï¼‰
        i_val, j_val = label_i.item(), label_j.item()
        return (j_val in anatomical_connections.get(i_val, [])) or \
               (i_val in anatomical_connections.get(j_val, []))
    
    def _should_update_label(self, i, j, distances, labels, threshold=3.0):
        """åŸºäºé‚»åŸŸæ ‡ç­¾ä¸€è‡´æ€§åˆ¤æ–­æ˜¯å¦æ›´æ–°æ ‡ç­¾"""
        # æ‰¾åˆ°èŠ‚ç‚¹içš„æ‰€æœ‰è¿‘é‚»
        neighbors = torch.where(distances[i] < threshold)[0]
        
        if len(neighbors) < 3:  # é‚»å±…å¤ªå°‘ï¼Œä¸è¿›è¡Œæ ‡ç­¾æ›´æ–°
            return False
            
        neighbor_labels = labels[neighbors]
        
        # ç»Ÿè®¡é‚»åŸŸæ ‡ç­¾åˆ†å¸ƒ
        label_counts = torch.bincount(neighbor_labels, minlength=self.num_classes)
        most_common_label = torch.argmax(label_counts)
        
        # å¦‚æœå½“å‰æ ‡ç­¾ä¸æ˜¯é‚»åŸŸä¸»è¦æ ‡ç­¾ä¸”ä¸»è¦æ ‡ç­¾æœ‰è¶³å¤Ÿæ”¯æŒï¼Œè€ƒè™‘æ›´æ–°
        return (labels[i] != most_common_label and 
                label_counts[most_common_label] >= 3 and
                label_counts[most_common_label] > label_counts[labels[i]])
    
    def plot_confusion_matrix(self, y_true, y_pred, epoch=None, show_percentages=True):
        """
        ğŸ“Š ç»˜åˆ¶å¢å¼ºç‰ˆæ··æ·†çŸ©é˜µ
        
        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred: é¢„æµ‹æ ‡ç­¾
            epoch: å½“å‰epochï¼ˆç”¨äºæ–‡ä»¶åï¼‰
            show_percentages: æ˜¯å¦æ˜¾ç¤ºç™¾åˆ†æ¯”
        """
        print(f"ğŸ“Š ç”Ÿæˆæ··æ·†çŸ©é˜µ (æ ·æœ¬æ•°: {len(y_true)})")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(y_true, torch.Tensor):
            y_true = y_true.cpu().numpy()
        if isinstance(y_pred, torch.Tensor):
            y_pred = y_pred.cpu().numpy()
        
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_true, y_pred, labels=range(self.num_classes))
        
        # å‡†å¤‡æ³¨é‡Šæ•°æ®
        if show_percentages:
            cm_percent = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-8) * 100
            annot_data = np.array([[f'{cm[i,j]}\n({cm_percent[i,j]:.1f}%)' 
                                  if cm[i,j] > 0 else ''
                                  for j in range(cm.shape[1])] 
                                 for i in range(cm.shape[0])])
        else:
            annot_data = cm
        
        # åˆ›å»ºå›¾å½¢
        plt.figure(figsize=(16, 14))
        
        # ä½¿ç”¨æ›´å¥½çš„é¢œè‰²æ˜ å°„
        mask = cm == 0
        sns.heatmap(cm, 
                   annot=annot_data, 
                   fmt='' if show_percentages else 'd',
                   cmap="Blues", 
                   xticklabels=self.class_names, 
                   yticklabels=self.class_names,
                   cbar_kws={'label': 'Sample Count'},
                   mask=mask,
                   linewidths=0.5,
                   square=True)
        
        plt.xlabel("Predicted Label", fontsize=14, fontweight='bold')
        plt.ylabel("True Label", fontsize=14, fontweight='bold')
        
        title = "CPR-TaG-Net è¡€ç®¡åˆ†ç±»æ··æ·†çŸ©é˜µ"
        if epoch is not None:
            title += f" (Epoch {epoch})"
        plt.title(title, fontsize=16, fontweight='bold', pad=20)
        
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        save_name = f"confusion_matrix_epoch_{epoch}.png" if epoch else "confusion_matrix.png"
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"   ğŸ’¾ å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        # æ‰“å°åˆ†ç±»æŠ¥å‘Š
        print("\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
        try:
            report = classification_report(y_true, y_pred, 
                                         target_names=self.class_names,
                                         labels=range(self.num_classes),
                                         zero_division=0)
            print(report)
            
            # ä¿å­˜åˆ†ç±»æŠ¥å‘Š
            report_path = self.save_dir / f"classification_report_epoch_{epoch}.txt" if epoch else self.save_dir / "classification_report.txt"
            with open(report_path, 'w') as f:
                f.write(report)
            print(f"   ğŸ’¾ åˆ†ç±»æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            
        except Exception as e:
            print(f"   âš ï¸ åˆ†ç±»æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
    
    def analyze_prediction_quality(self, y_true, y_pred, positions=None):
        """
        ğŸ” åˆ†æé¢„æµ‹è´¨é‡å’Œé”™è¯¯æ¨¡å¼
        
        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred: é¢„æµ‹æ ‡ç­¾
            positions: èŠ‚ç‚¹ä½ç½®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            analysis: åˆ†æç»“æœå­—å…¸
        """
        print(f"ğŸ” åˆ†æé¢„æµ‹è´¨é‡")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(y_true, torch.Tensor):
            y_true = y_true.cpu().numpy()
        if isinstance(y_pred, torch.Tensor):
            y_pred = y_pred.cpu().numpy()
        
        analysis = {
            'total_samples': len(y_true),
            'overall_accuracy': float((y_true == y_pred).sum() / len(y_true)),
            'class_accuracy': {},
            'class_support': {},
            'error_patterns': defaultdict(int),
            'difficult_classes': [],
            'well_classified_classes': []
        }
        
        # æŒ‰ç±»åˆ«åˆ†æå‡†ç¡®ç‡
        for class_idx, class_name in enumerate(self.class_names):
            mask = (y_true == class_idx)
            support = mask.sum()
            analysis['class_support'][class_name] = int(support)
            
            if support > 0:
                class_acc = float((y_pred[mask] == class_idx).sum() / support)
                analysis['class_accuracy'][class_name] = class_acc
                
                if class_acc < 0.5:  # å‡†ç¡®ç‡ä½äº50%çš„å›°éš¾ç±»åˆ«
                    analysis['difficult_classes'].append((class_name, class_acc))
                elif class_acc > 0.8:  # å‡†ç¡®ç‡é«˜äº80%çš„è‰¯å¥½ç±»åˆ«
                    analysis['well_classified_classes'].append((class_name, class_acc))
        
        # åˆ†æé”™è¯¯æ¨¡å¼
        errors = y_true != y_pred
        if errors.sum() > 0:
            for true_label, pred_label in zip(y_true[errors], y_pred[errors]):
                if 0 <= true_label < len(self.class_names) and 0 <= pred_label < len(self.class_names):
                    error_pattern = f"{self.class_names[true_label]} -> {self.class_names[pred_label]}"
                    analysis['error_patterns'][error_pattern] += 1
        
        # æ’åºå›°éš¾ç±»åˆ«å’Œé”™è¯¯æ¨¡å¼
        analysis['difficult_classes'] = sorted(analysis['difficult_classes'], key=lambda x: x[1])
        analysis['error_patterns'] = dict(sorted(analysis['error_patterns'].items(), 
                                                key=lambda x: x[1], reverse=True)[:10])  # å‰10ä¸ªé”™è¯¯æ¨¡å¼
        
        # æ‰“å°åˆ†æç»“æœ
        print(f"   æ€»ä½“å‡†ç¡®ç‡: {analysis['overall_accuracy']:.4f}")
        print(f"   å›°éš¾ç±»åˆ«æ•°: {len(analysis['difficult_classes'])}")
        print(f"   ä¸»è¦é”™è¯¯æ¨¡å¼æ•°: {len(analysis['error_patterns'])}")
        
        if analysis['difficult_classes']:
            print("   ğŸ”´ å›°éš¾ç±»åˆ«:")
            for class_name, acc in analysis['difficult_classes'][:5]:
                print(f"      {class_name}: {acc:.3f}")
        
        if analysis['error_patterns']:
            print("   âš ï¸ ä¸»è¦é”™è¯¯æ¨¡å¼:")
            for pattern, count in list(analysis['error_patterns'].items())[:3]:
                print(f"      {pattern}: {count} æ¬¡")
        
        return analysis
    
    def visualize_training_progress(self, train_losses, train_accs, val_losses=None, val_accs=None, epoch=None):
        """
        ğŸ“ˆ å¯è§†åŒ–è®­ç»ƒè¿›åº¦
        
        Args:
            train_losses: è®­ç»ƒæŸå¤±åˆ—è¡¨
            train_accs: è®­ç»ƒå‡†ç¡®ç‡åˆ—è¡¨
            val_losses: éªŒè¯æŸå¤±åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            val_accs: éªŒè¯å‡†ç¡®ç‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            epoch: å½“å‰epochï¼ˆç”¨äºæ–‡ä»¶åï¼‰
        """
        print(f"ğŸ“ˆ ç”Ÿæˆè®­ç»ƒè¿›åº¦å›¾è¡¨")
        
        epochs = range(1, len(train_losses) + 1)
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('CPR-TaG-Net è®­ç»ƒè¿›åº¦ç›‘æ§', fontsize=16, fontweight='bold')
        
        # è®­ç»ƒæŸå¤±
        axes[0, 0].plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2, marker='o', markersize=3)
        if val_losses:
            val_epochs = range(1, len(val_losses) + 1)
            axes[0, 0].plot(val_epochs, val_losses, 'r--', label='Validation Loss', linewidth=2, marker='s', markersize=3)
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].set_title('è®­ç»ƒæŸå¤±æ›²çº¿')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # è®­ç»ƒå‡†ç¡®ç‡
        axes[0, 1].plot(epochs, train_accs, 'g-', label='Training Accuracy', linewidth=2, marker='o', markersize=3)
        if val_accs:
            val_epochs = range(1, len(val_accs) + 1)
            axes[0, 1].plot(val_epochs, val_accs, 'r--', label='Validation Accuracy', linewidth=2, marker='s', markersize=3)
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].set_title('è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].set_ylim(0, 1)
        
        # æŸå¤±å˜åŒ–ç‡
        if len(train_losses) > 1:
            loss_changes = np.diff(train_losses)
            axes[1, 0].plot(epochs[1:], loss_changes, 'purple', linewidth=2, marker='o', markersize=3)
            axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.5)
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Loss Change')
            axes[1, 0].set_title('æŸå¤±å˜åŒ–ç‡')
            axes[1, 0].grid(True, alpha=0.3)
        
        # å‡†ç¡®ç‡å˜åŒ–ç‡
        if len(train_accs) > 1:
            acc_changes = np.diff(train_accs)
            axes[1, 1].plot(epochs[1:], acc_changes, 'orange', linewidth=2, marker='o', markersize=3)
            axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Accuracy Change')
            axes[1, 1].set_title('å‡†ç¡®ç‡å˜åŒ–ç‡')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        save_name = f"training_progress_epoch_{epoch}.png" if epoch else "training_progress.png"
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"   ğŸ’¾ å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def save_analysis_report(self, analysis, epoch=None):
        """ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report_name = f"analysis_report_epoch_{epoch}.txt" if epoch else "analysis_report.txt"
        report_path = self.save_dir / report_name
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("CPR-TaG-Net é¢„æµ‹è´¨é‡åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ€»æ ·æœ¬æ•°: {analysis['total_samples']}\n")
            f.write(f"æ€»ä½“å‡†ç¡®ç‡: {analysis['overall_accuracy']:.4f}\n\n")
            
            f.write("å„ç±»åˆ«å‡†ç¡®ç‡:\n")
            for class_name, acc in analysis['class_accuracy'].items():
                support = analysis['class_support'][class_name]
                f.write(f"  {class_name}: {acc:.4f} (æ”¯æŒåº¦: {support})\n")
            
            f.write(f"\nå›°éš¾ç±»åˆ« (å‡†ç¡®ç‡ < 0.5):\n")
            for class_name, acc in analysis['difficult_classes']:
                f.write(f"  {class_name}: {acc:.4f}\n")
            
            f.write(f"\nä¸»è¦é”™è¯¯æ¨¡å¼:\n")
            for pattern, count in analysis['error_patterns'].items():
                f.write(f"  {pattern}: {count} æ¬¡\n")
        
        print(f"   ğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def create_enhanced_trainer(save_dir="outputs/visualizations"):
    """åˆ›å»ºå¢å¼ºè®­ç»ƒå·¥å…·å®ä¾‹"""
    return EnhancedTrainingUtils(save_dir=save_dir)

# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    # æµ‹è¯•å¢å¼ºè®­ç»ƒå·¥å…·
    trainer = create_enhanced_trainer()
    print("âœ… å¢å¼ºè®­ç»ƒå·¥å…·æµ‹è¯•å®Œæˆ")
