#!/usr/bin/env python3
"""
é‡æ–°å¤„ç†è¡€ç®¡æ•°æ®è„šæœ¬ - ä½¿ç”¨ä¿®å¤åçš„15ç±»è¡€ç®¡å±‚æ¬¡ç»“æ„
"""

import os
import sys
import shutil
import argparse
from pathlib import Path
import time

# æ·»åŠ srcè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src', 'preprocessing'))

def reprocess_vessel_data(args):
    """é‡æ–°å¤„ç†è¡€ç®¡æ•°æ®"""
    print("ğŸ”„ å¼€å§‹é‡æ–°å¤„ç†è¡€ç®¡æ•°æ®")
    print("=" * 60)
    
    # æ£€æŸ¥è·¯å¾„
    ct_dir = args.ct_dir
    label_dir = args.label_dir
    output_dir = args.output_dir
    
    print(f"ğŸ“‚ CTæ•°æ®ç›®å½•: {ct_dir}")
    print(f"ğŸ“‚ æ ‡ç­¾æ•°æ®ç›®å½•: {label_dir}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    
    # éªŒè¯è¾“å…¥è·¯å¾„
    if not os.path.exists(ct_dir):
        print(f"âŒ CTæ•°æ®ç›®å½•ä¸å­˜åœ¨: {ct_dir}")
        return False
        
    if not os.path.exists(label_dir):
        print(f"âŒ æ ‡ç­¾æ•°æ®ç›®å½•ä¸å­˜åœ¨: {label_dir}")
        return False
    
    # å¤‡ä»½ç°æœ‰æ•°æ®
    if os.path.exists(output_dir) and args.backup_existing:
        backup_dir = f"{output_dir}_backup_{int(time.time())}"
        print(f"ğŸ’¾ å¤‡ä»½ç°æœ‰æ•°æ®åˆ°: {backup_dir}")
        shutil.copytree(output_dir, backup_dir)
    
    # æ¸…ç†ç°æœ‰æ•°æ®
    if args.clean_existing and os.path.exists(output_dir):
        print("ğŸ§¹ æ¸…ç†ç°æœ‰å¤„ç†åæ•°æ®...")
        shutil.rmtree(output_dir)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # å¯¼å…¥å¹¶åˆ›å»ºé¢„å¤„ç†å™¨
    try:
        from vessel_preprocessing import VesselPreprocessor
        print("âœ… æˆåŠŸå¯¼å…¥è¡€ç®¡é¢„å¤„ç†æ¨¡å—")
        
        preprocessor = VesselPreprocessor(
            ct_dir=ct_dir,
            label_dir=label_dir,
            output_dir=output_dir,
            cube_size=args.cube_size
        )
        print("âœ… è¡€ç®¡é¢„å¤„ç†å™¨å·²åˆå§‹åŒ–")
        
        # éªŒè¯è¡€ç®¡å±‚æ¬¡ç»“æ„
        print("ğŸ” éªŒè¯è¡€ç®¡å±‚æ¬¡ç»“æ„...")
        vessel_hierarchy = preprocessor.vessel_hierarchy
        print(f"  è¡€ç®¡ç±»å‹æ•°: {len(vessel_hierarchy)}")
        print(f"  è¡€ç®¡ç±»å‹: {list(vessel_hierarchy.keys())}")
        
        if len(vessel_hierarchy) == 15:
            print("  âœ… è¡€ç®¡æ•°é‡æ­£ç¡®: 15ç±»")
        else:
            print(f"  âš ï¸ è¡€ç®¡æ•°é‡: {len(vessel_hierarchy)}ç±» (æœŸæœ›15ç±»)")
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é¢„å¤„ç†æ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ åˆ›å»ºé¢„å¤„ç†å™¨å¤±è´¥: {e}")
        return False
    
    # å¼€å§‹å¤„ç†
    print(f"\nğŸš€ å¼€å§‹å¤„ç†è¡€ç®¡æ•°æ®...")
    
    try:
        # è°ƒç”¨é¢„å¤„ç†å™¨å¤„ç†æ‰€æœ‰æ¡ˆä¾‹
        results = preprocessor.process_all_cases()
        
        if results:
            print(f"ğŸ‰ å¤„ç†å®Œæˆ!")
            print(f"ğŸ“Š æˆåŠŸå¤„ç†æ¡ˆä¾‹æ•°: {len(results)}")
            print(f"ï¿½ è¾“å‡ºç›®å½•: {output_dir}")
            
            # éªŒè¯å¤„ç†ç»“æœ
            print(f"\nğŸ” éªŒè¯å¤„ç†ç»“æœ...")
            validate_processed_data(output_dir, args.verbose)
            
            return True
        else:
            print("âŒ æœªèƒ½å¤„ç†ä»»ä½•æ¡ˆä¾‹")
            return False
            
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return False

def validate_processed_data(output_dir, verbose=False):
    """éªŒè¯å¤„ç†åçš„æ•°æ®"""
    import numpy as np
    
    processed_files = list(Path(output_dir).glob("*_processed.npz"))
    
    if not processed_files:
        print("âš ï¸ æœªæ‰¾åˆ°å¤„ç†åçš„æ–‡ä»¶")
        return
    
    print(f"ğŸ” éªŒè¯ {len(processed_files)} ä¸ªå¤„ç†åçš„æ–‡ä»¶...")
    
    total_nodes = 0
    total_edges = 0
    vessel_types = set()
    class_ranges = set()
    valid_files = 0
    
    for file_path in processed_files:
        try:
            data = np.load(file_path, allow_pickle=True)
            
            # åŸºæœ¬æ£€æŸ¥
            required_keys = ['node_features', 'node_positions', 'edge_index', 
                           'node_classes', 'vessel_node_ranges']
            
            missing_keys = [key for key in required_keys if key not in data.keys()]
            if missing_keys:
                print(f"  âŒ {file_path.name}: ç¼ºå¤±é”® {missing_keys}")
                continue
            
            # ç»Ÿè®¡ä¿¡æ¯
            node_count = len(data['node_features'])
            edge_count = data['edge_index'].shape[1] if data['edge_index'].size > 0 else 0
            vessel_ranges = data['vessel_node_ranges'].item()
            node_classes = data['node_classes']
            
            total_nodes += node_count
            total_edges += edge_count
            vessel_types.update(vessel_ranges.keys())
            class_ranges.update(np.unique(node_classes))
            valid_files += 1
            
            if verbose:
                print(f"  âœ… {file_path.name}: {node_count} èŠ‚ç‚¹, {edge_count} è¾¹, {len(vessel_ranges)} è¡€ç®¡")
                
        except Exception as e:
            print(f"  âŒ {file_path.name}: éªŒè¯é”™è¯¯ {e}")
    
    if valid_files == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å¤„ç†æ–‡ä»¶")
        return
    
    print(f"ğŸ“Š éªŒè¯ç»Ÿè®¡:")
    print(f"  æœ‰æ•ˆæ–‡ä»¶: {valid_files}/{len(processed_files)}")
    print(f"  æ€»èŠ‚ç‚¹æ•°: {total_nodes:,}")
    print(f"  æ€»è¾¹æ•°: {total_edges:,}")
    print(f"  è¡€ç®¡ç±»å‹æ•°: {len(vessel_types)}")
    print(f"  è¡€ç®¡ç±»å‹: {sorted(vessel_types)}")
    print(f"  ç±»åˆ«èŒƒå›´: {sorted(class_ranges)}")
    
    # æ£€æŸ¥è¡€ç®¡å±‚æ¬¡ç»“æ„
    if len(vessel_types) == 15:
        print("  âœ… è¡€ç®¡æ•°é‡æ­£ç¡®: 15ç±»")
    else:
        print(f"  âš ï¸ è¡€ç®¡æ•°é‡: {len(vessel_types)}ç±» (æœŸæœ›15ç±»)")
    
    if len(class_ranges) <= 15 and min(class_ranges) >= 0:
        print(f"  âœ… ç±»åˆ«èŒƒå›´åˆç†: {min(class_ranges)}-{max(class_ranges)}")
    else:
        print(f"  âš ï¸ ç±»åˆ«èŒƒå›´å¼‚å¸¸: {min(class_ranges)}-{max(class_ranges)}")

def main():
    parser = argparse.ArgumentParser(description='é‡æ–°å¤„ç†è¡€ç®¡æ•°æ®')
    
    # è·¯å¾„å‚æ•°
    parser.add_argument('--ct_dir', type=str, 
                       default='/home/lihe/classify/lungmap/data/raw/train',
                       help='CTæ•°æ®ç›®å½•')
    parser.add_argument('--label_dir', type=str,
                       default='/home/lihe/classify/lungmap/data/raw/label_filtered',
                       help='æ ‡ç­¾æ•°æ®ç›®å½•')
    parser.add_argument('--output_dir', type=str,
                       default='/home/lihe/classify/lungmap/data/processed',
                       help='å¤„ç†åæ•°æ®è¾“å‡ºç›®å½•')
    
    # å¤„ç†å‚æ•°
    parser.add_argument('--cube_size', type=int, default=32,
                       help='å›¾åƒå—å¤§å°')
    
    # æ§åˆ¶å‚æ•°
    parser.add_argument('--clean_existing', action='store_true',
                       help='æ¸…ç†ç°æœ‰çš„å¤„ç†åæ•°æ®')
    parser.add_argument('--backup_existing', action='store_true',
                       help='å¤‡ä»½ç°æœ‰çš„å¤„ç†åæ•°æ®')
    parser.add_argument('--verbose', action='store_true',
                       help='è¯¦ç»†è¾“å‡ºå¤„ç†ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºé…ç½®
    print("ğŸ”§ æ•°æ®é‡æ–°å¤„ç†é…ç½®:")
    print(f"  CTæ•°æ®ç›®å½•: {args.ct_dir}")
    print(f"  æ ‡ç­¾æ•°æ®ç›®å½•: {args.label_dir}")
    print(f"  è¾“å‡ºæ•°æ®ç›®å½•: {args.output_dir}")
    print(f"  å›¾åƒå—å¤§å°: {args.cube_size}")
    print(f"  æ¸…ç†ç°æœ‰æ•°æ®: {'æ˜¯' if args.clean_existing else 'å¦'}")
    print(f"  å¤‡ä»½ç°æœ‰æ•°æ®: {'æ˜¯' if args.backup_existing else 'å¦'}")
    
    # ç¡®è®¤æ“ä½œ
    if args.clean_existing:
        response = input("âš ï¸ ç¡®å®šè¦æ¸…ç†ç°æœ‰çš„å¤„ç†åæ•°æ®å—ï¼Ÿè¿™å°†åˆ é™¤æ‰€æœ‰ç°æœ‰çš„.npzæ–‡ä»¶ (y/N): ")
        if response.lower() != 'y':
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
    
    # å¼€å§‹å¤„ç†
    success = reprocess_vessel_data(args)
    
    if success:
        print("\nğŸ‰ æ•°æ®é‡æ–°å¤„ç†å®Œæˆ!")
        print("ğŸ“ å»ºè®®æ¥ä¸‹æ¥:")
        print("  1. è¿è¡Œè®­ç»ƒå‰éªŒè¯: python validate_processed_data.py")
        print("  2. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§: python test_all_vessel_consistency.py") 
        print("  3. å¼€å§‹è®­ç»ƒ: python train.py --enable_large_cases")
    else:
        print("\nâŒ æ•°æ®é‡æ–°å¤„ç†å¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()
