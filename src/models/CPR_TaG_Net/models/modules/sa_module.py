import torch
import torch.nn as nn
from torch_scatter import scatter_max
from torch_geometric.nn import GCNConv
import torch.nn.functional as F
from torch_geometric.utils import degree

def topology_preserving_sampling(nodes, edges, sample_ratio=0.5):
    """
    ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šç¡®ä¿æ‰€æœ‰å¼ é‡æ“ä½œçš„ç»´åº¦ä¸€è‡´æ€§
    nodes: [N, 3]
    edges: [2, E]
    return: sampled_nodes_idx: index of preserved nodes
    """
    N = nodes.shape[0]
    device = nodes.device

    # è¾¹ç•Œæ£€æŸ¥
    if N == 0:
        return torch.tensor([], dtype=torch.long, device=device)
    
    # å¤„ç†ç©ºè¾¹æƒ…å†µ
    if edges.shape[1] == 0:
        num_sample = max(1, int(sample_ratio * N))
        return torch.randperm(N, device=device)[:num_sample]

    try:
        # Step 1: è®¡ç®—æ¯ä¸ªç‚¹çš„åº¦æ•°
        deg = degree(edges[0], N)  # [N]

        # Step 2: æ‰¾å‡ºæ‹“æ‰‘å…³é”®ç‚¹ï¼ˆç«¯ç‚¹æˆ–åˆ†å‰ç‚¹ï¼‰
        key_nodes_idx = torch.where(deg != 2)[0]  # [K] - 1Då¼ é‡

        # Step 3: å…¶ä½™ç‚¹ä¸­åš FPSï¼ˆè¿œç‚¹é‡‡æ ·ï¼‰
        normal_nodes_idx = torch.where(deg == 2)[0]  # [F] - 1Då¼ é‡
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿ç»´åº¦è®¡ç®—æ­£ç¡®
        key_count = len(key_nodes_idx)
        normal_count = len(normal_nodes_idx)
        target_sample_count = max(1, int(sample_ratio * N))
        fps_sample_count = max(0, target_sample_count - key_count)
        
        if fps_sample_count > 0 and normal_count > 0:
            fps_sample_count = min(fps_sample_count, normal_count)
            fps_nodes_idx = farthest_point_sampling(nodes[normal_nodes_idx], fps_sample_count)
            
            # ğŸ”§ ç¡®ä¿æ‰€æœ‰å¼ é‡éƒ½æ˜¯1Då¹¶ä¸”å…¼å®¹
            if len(fps_nodes_idx) > 0:
                selected_normal = normal_nodes_idx[fps_nodes_idx]  # [fps_sample_count]
                
                # ç¡®ä¿ä¸¤ä¸ªå¼ é‡éƒ½æ˜¯1D
                key_nodes_flat = key_nodes_idx.flatten()
                selected_normal_flat = selected_normal.flatten()
                
                selected_idx = torch.cat([key_nodes_flat, selected_normal_flat])  # [K + fps_sample_count]
            else:
                selected_idx = key_nodes_idx.flatten()
        else:
            selected_idx = key_nodes_idx.flatten() if len(key_nodes_idx) > 0 else torch.tensor([0], device=device)

        return selected_idx
        
    except Exception as e:
        print(f"âš ï¸  Error in topology_preserving_sampling: {e}")
        # é™çº§ï¼šéšæœºé‡‡æ ·
        num_sample = max(1, int(sample_ratio * N))
        return torch.randperm(N, device=device)[:num_sample]

def farthest_point_sampling(xyz, n_sample):
    """
    ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šåŠ å¼ºè¾¹ç•Œæ£€æŸ¥å’Œç»´åº¦ä¿è¯
    xyz: [M, 3]
    return: [n_sample] index of sampled points using FPS
    """
    N = xyz.shape[0]
    device = xyz.device
    
    # ä¸¥æ ¼çš„è¾¹ç•Œæ£€æŸ¥
    if N == 0 or n_sample == 0:
        return torch.tensor([], dtype=torch.long, device=device)
    
    if n_sample >= N:
        return torch.arange(N, dtype=torch.long, device=device)
    
    try:
        centroids = torch.zeros(n_sample, dtype=torch.long, device=device)
        distance = torch.ones(N, device=device) * 1e10
        farthest = torch.randint(0, N, (1,), dtype=torch.long, device=device).item()

        for i in range(n_sample):
            centroids[i] = farthest
            centroid = xyz[farthest:farthest+1, :]  # [1, 3] - ç¡®ä¿ç»´åº¦
            dist = torch.sum((xyz - centroid) ** 2, dim=1)  # [N]
            distance = torch.min(distance, dist)
            farthest = torch.argmax(distance).item()

        return centroids  # [n_sample] - ä¿è¯1D
        
    except Exception as e:
        print(f"âš ï¸  Error in FPS: {e}")
        # é™çº§ï¼šéšæœºé‡‡æ ·
        return torch.randperm(N, device=device)[:n_sample]


def topology_aware_grouping(sampled_nodes_idx, full_edges, k=8):
    """
    ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šè¿”å›ç›¸å¯¹äºé‡‡æ ·èŠ‚ç‚¹çš„ç´¢å¼•
    sampled_nodes_idx: é‡‡æ ·åçš„ [M] - åŸå§‹å›¾ä¸­çš„èŠ‚ç‚¹ç´¢å¼•
    full_edges: åŸå§‹æ‹“æ‰‘å›¾ [2, E]
    return: groups: [M, k] - ç›¸å¯¹äºé‡‡æ ·èŠ‚ç‚¹çš„ç´¢å¼• (0åˆ°M-1)
    """
    M = sampled_nodes_idx.shape[0]
    device = sampled_nodes_idx.device
    
    if M == 0:
        return torch.empty((0, k), dtype=torch.long, device=device)

    try:
        edge_index = full_edges.cpu().numpy()
        sampled_idx_list = sampled_nodes_idx.tolist()
        sampled_idx_set = set(sampled_idx_list)

        # å»ºç«‹é‚»æ¥è¡¨
        from collections import defaultdict
        adj_dict = defaultdict(set)
        for src, tgt in edge_index.T:
            adj_dict[src].add(tgt)
            adj_dict[tgt].add(src)

        groups = []
        for i, original_idx in enumerate(sampled_idx_list):  # iæ˜¯ç›¸å¯¹ç´¢å¼•ï¼Œoriginal_idxæ˜¯åŸå§‹ç´¢å¼•
            neighbors = list(adj_dict[original_idx])
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†é‚»å±…çš„åŸå§‹ç´¢å¼•è½¬æ¢ä¸ºç›¸å¯¹ç´¢å¼•
            valid_neighbors = []
            for neighbor_original_idx in neighbors:
                if neighbor_original_idx in sampled_idx_set:
                    # æ‰¾åˆ°é‚»å±…åœ¨é‡‡æ ·èŠ‚ç‚¹ä¸­çš„ç›¸å¯¹ä½ç½®
                    try:
                        relative_idx = sampled_idx_list.index(neighbor_original_idx)
                        valid_neighbors.append(relative_idx)
                    except ValueError:
                        continue
            
            # è¡¥é½åˆ°kä¸ªé‚»å±…
            if len(valid_neighbors) >= k:
                groups.append(valid_neighbors[:k])
            else:
                # ç”¨è‡ªå·±çš„ç›¸å¯¹ç´¢å¼•è¡¥é½ï¼ˆè‡ªç¯ï¼‰
                padding_needed = k - len(valid_neighbors)
                groups.append(valid_neighbors + [i] * padding_needed)

        # ğŸ”§ ç¡®ä¿è¿”å›æ­£ç¡®ç»´åº¦
        if len(groups) != M:
            print(f"âš ï¸  Group count mismatch: expected {M}, got {len(groups)}")
            # åˆ›å»ºé»˜è®¤åˆ†ç»„
            groups = [[i] * k for i in range(M)]

        result = torch.tensor(groups, dtype=torch.long, device=device)  # [M, k]
        
        # æœ€ç»ˆç»´åº¦æ£€æŸ¥
        if result.shape != (M, k):
            print(f"âš ï¸  Final shape mismatch: expected ({M}, {k}), got {result.shape}")
            result = torch.zeros((M, k), dtype=torch.long, device=device)
            for i in range(M):
                result[i, :] = i  # è‡ªç¯åˆ†ç»„ä½œä¸ºé™çº§
        
        return result
        
    except Exception as e:
        print(f"âš ï¸  Error in topology_aware_grouping: {e}")
        # é™çº§å¤„ç†ï¼šè¿”å›è‡ªç¯åˆ†ç»„
        result = torch.zeros((M, k), dtype=torch.long, device=device)
        for i in range(M):
            result[i, :] = i
        return result


class PointNetUnit(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(in_channels, out_channels),
            nn.ReLU(),
            nn.Linear(out_channels, out_channels)
        )

    def forward(self, group_feats):  # [M, k, C]
        try:
            # ğŸ”§ æ·»åŠ è¾“å…¥éªŒè¯
            if group_feats.dim() != 3:
                print(f"âš ï¸  PointNetUnit input dimension error: expected 3D, got {group_feats.dim()}D, shape={group_feats.shape}")
                return torch.zeros((group_feats.shape[0], self.mlp[-1].out_features), device=group_feats.device)
            
            x = self.mlp(group_feats)  # [M, k, C']
            x, _ = torch.max(x, dim=1)  # [M, C']
            return x
            
        except Exception as e:
            print(f"âš ï¸  PointNetUnit error: {e}")
            M = group_feats.shape[0]
            return torch.zeros((M, self.mlp[-1].out_features), device=group_feats.device)


class TopoSAModule(nn.Module):
    def __init__(self, in_channels, out_channels, k=8, sample_ratio=0.5):
        super().__init__()
        self.k = k
        self.sample_ratio = sample_ratio
        self.pointnet = PointNetUnit(in_channels, out_channels)
        self.gcn = GCNConv(out_channels, out_channels)

    def forward(self, x, pos, edge_index):
        try:
            # ğŸ”§ ä¸¥æ ¼çš„è¾“å…¥éªŒè¯
            if x.shape[0] != pos.shape[0]:
                print(f"âš ï¸  Input size mismatch: x={x.shape}, pos={pos.shape}")
                return x, pos, edge_index
            
            if pos.shape[1] != 3:
                print(f"âš ï¸  Position dimension error: expected [N, 3], got {pos.shape}")
                return x, pos, edge_index
                
            # Step 1: TPS é‡‡æ ·èŠ‚ç‚¹
            sampled_idx = topology_preserving_sampling(pos, edge_index, self.sample_ratio)
            
            if len(sampled_idx) == 0:
                empty_feat = torch.zeros((0, self.pointnet.mlp[-1].out_features), device=x.device)
                empty_pos = torch.zeros((0, 3), device=x.device)
                empty_edges = torch.zeros((2, 0), dtype=torch.long, device=x.device)
                return empty_feat, empty_pos, empty_edges
                
            # Step 2: æå–é‡‡æ ·åçš„æ•°æ®
            pos_out = pos[sampled_idx]  # [M, 3]
            x_sampled = x[sampled_idx]  # [M, C]

            # Step 3: è·å–åˆ†ç»„ç´¢å¼•
            group_idx = topology_aware_grouping(sampled_idx, edge_index, k=self.k)  # [M, k]
            
            # Step 4: ğŸ”§ ä¸¥æ ¼çš„ç»´åº¦æ£€æŸ¥
            M, C = x_sampled.shape
            if group_idx.shape != (M, self.k):
                print(f"âš ï¸  Group index shape error: expected ({M}, {self.k}), got {group_idx.shape}")
                # ä½¿ç”¨é™çº§åˆ†ç»„
                group_idx = torch.zeros((M, self.k), dtype=torch.long, device=x.device)
                for i in range(M):
                    group_idx[i, :] = i
            
            # æ£€æŸ¥ç´¢å¼•èŒƒå›´
            if (group_idx < 0).any() or (group_idx >= M).any():
                print(f"âš ï¸  Invalid indices: min={group_idx.min()}, max={group_idx.max()}, valid_range=[0, {M-1}]")
                group_idx = torch.clamp(group_idx, 0, M-1)

            # Step 5: æå–åˆ†ç»„ç‰¹å¾
            group_feat = x_sampled[group_idx]  # [M, k, C]
            
            # ğŸ”§ æœ€ç»ˆç»´åº¦éªŒè¯
            if group_feat.shape != (M, self.k, C):
                print(f"âš ï¸  Group feature shape error: expected ({M}, {self.k}, {C}), got {group_feat.shape}")
                group_feat = x_sampled.unsqueeze(1).expand(-1, self.k, -1)  # é™çº§å¤„ç†
            
            point_feat = self.pointnet(group_feat)  # [M, C']

            # Step 6: é‡å»ºå­å›¾
            new_edge_index = self._rebuild_subgraph_edges(sampled_idx, edge_index, x.device)
            x_out = self.gcn(point_feat, new_edge_index)

            return x_out, pos_out, new_edge_index
            
        except Exception as e:
            print(f"âš ï¸  TopoSAModule critical error: {e}")
            print(f"    Input shapes: x={x.shape}, pos={pos.shape}, edge_index={edge_index.shape}")
            # å®Œå…¨é™çº§ï¼šè¿”å›è¾“å…¥
            return x, pos, edge_index
    
    def _rebuild_subgraph_edges(self, sampled_idx, edge_index, device):
        """é‡å»ºå­å›¾è¾¹è¿æ¥"""
        try:
            if len(sampled_idx) <= 1:
                return torch.empty((2, 0), dtype=torch.long, device=device)
                
            idx_map = {idx.item(): i for i, idx in enumerate(sampled_idx)}
            new_edges = []
            
            for original_idx in sampled_idx:
                neighbors = edge_index[1][edge_index[0] == original_idx]
                for neighbor_idx in neighbors:
                    if neighbor_idx.item() in idx_map:
                        src_new = idx_map[original_idx.item()]
                        tgt_new = idx_map[neighbor_idx.item()]
                        new_edges.append([src_new, tgt_new])
            
            if len(new_edges) == 0:
                return torch.empty((2, 0), dtype=torch.long, device=device)
            else:
                return torch.tensor(new_edges, dtype=torch.long, device=device).T
                
        except Exception as e:
            print(f"âš ï¸  Error rebuilding subgraph: {e}")
            return torch.empty((2, 0), dtype=torch.long, device=device)