#!/usr/bin/env python3
"""
è¡€ç®¡åˆ†ç±»è®­ç»ƒå¯åŠ¨è„šæœ¬
ç®€åŒ–ç‰ˆæœ¬ï¼Œä¾¿äºå¿«é€Ÿå¼€å§‹è®­ç»ƒ
"""

import subprocess
import sys
import os

def check_gpu():
    """æ£€æŸ¥GPUçŠ¶æ€"""
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            for line in lines:
                if 'MiB' in line and '/' in line:
                    # æå–æ˜¾å­˜ä¿¡æ¯
                    parts = line.split()
                    for i, part in enumerate(parts):
                        if 'MiB' in part and i > 0:
                            used = parts[i-1]
                            total = part.replace('MiB', '')
                            print(f"ğŸ“Š GPUæ˜¾å­˜: {used}MiB / {total}MiB")
                            total_gb = int(total) / 1024
                            if total_gb >= 20:
                                print(f"âœ… æ£€æµ‹åˆ° {total_gb:.1f}GB æ˜¾å­˜ï¼Œå¯ä»¥å¯ç”¨å¤§æ¡ˆä¾‹è®­ç»ƒ")
                                return True
                            else:
                                print(f"âš ï¸  æ˜¾å­˜è¾ƒå° ({total_gb:.1f}GB)ï¼Œå»ºè®®ä½¿ç”¨ä¿å®ˆæ¨¡å¼")
                                return False
    except:
        print("âš ï¸  æ— æ³•æ£€æµ‹GPUçŠ¶æ€")
        return False

def main():
    print("ğŸš€ CPR-TaG-Net è¡€ç®¡åˆ†ç±»è®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥å½“å‰ç›®å½•
    if not os.path.exists('train.py'):
        print("âŒ è¯·åœ¨ lungmap é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        sys.exit(1)
    
    # æ£€æŸ¥æ•°æ®
    if not os.path.exists('data/processed'):
        print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: data/processed")
        sys.exit(1)
    
    processed_files = os.listdir('data/processed')
    npz_files = [f for f in processed_files if f.endswith('.npz')]
    print(f"ğŸ“ æ‰¾åˆ° {len(npz_files)} ä¸ªé¢„å¤„ç†æ•°æ®æ–‡ä»¶")
    
    if len(npz_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°é¢„å¤„ç†æ•°æ®æ–‡ä»¶ (.npz)")
        sys.exit(1)
    
    # æ£€æŸ¥GPU
    has_large_gpu = check_gpu()
    
    print("\nğŸ”§ è®­ç»ƒé…ç½®é€‰é¡¹:")
    print("1. å¿«é€Ÿæµ‹è¯•æ¨¡å¼ (å°æ•°æ®é›†, 10è½®)")
    print("2. æ ‡å‡†è®­ç»ƒæ¨¡å¼ (ä¸­ç­‰æ•°æ®é›†, 50è½®)")
    print("3. å®Œæ•´è®­ç»ƒæ¨¡å¼ (å¤§æ•°æ®é›†, 100è½®) - éœ€è¦å¤§æ˜¾å­˜")
    print("4. è‡ªå®šä¹‰å‚æ•°")
    
    choice = input("\nè¯·é€‰æ‹©è®­ç»ƒæ¨¡å¼ [1-4]: ").strip()
    
    # åŸºç¡€å‘½ä»¤
    base_cmd = [
        'conda', 'run', '--live-stream', '--name', 'lungmap', 'python', 'train.py'
    ]
    
    if choice == '1':
        # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
        cmd = base_cmd + [
            '--epochs', '10',
            '--max_nodes', '500',
            '--node_batch_size', '200',
            '--save_freq', '2',
            '--enable_visualization',
            '--save_training_curves'
        ]
        print("ğŸ”§ ä½¿ç”¨å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
        
    elif choice == '2':
        # æ ‡å‡†è®­ç»ƒæ¨¡å¼
        cmd = base_cmd + [
            '--epochs', '50',
            '--max_nodes', '2000',
            '--node_batch_size', '300',
            '--save_freq', '5',
            '--enable_vessel_aware',
            '--enable_visualization',
            '--save_training_curves',
            '--save_confusion_matrix'
        ]
        print("ğŸ”§ ä½¿ç”¨æ ‡å‡†è®­ç»ƒæ¨¡å¼")
        
    elif choice == '3':
        # å®Œæ•´è®­ç»ƒæ¨¡å¼
        if not has_large_gpu:
            print("âš ï¸  æ£€æµ‹åˆ°æ˜¾å­˜å¯èƒ½ä¸è¶³ï¼Œå»ºè®®é€‰æ‹©æ¨¡å¼1æˆ–2")
            confirm = input("æ˜¯å¦ç»§ç»­? [y/N]: ").strip().lower()
            if confirm != 'y':
                return
        
        cmd = base_cmd + [
            '--epochs', '100',
            '--enable_large_cases',
            '--max_nodes_per_case', '8000',
            '--node_batch_size', '500',
            '--save_freq', '10',
            '--enable_vessel_aware',
            '--enable_visualization',
            '--save_training_curves',
            '--save_confusion_matrix',
            '--enable_graph_completion'
        ]
        print("ğŸ”§ ä½¿ç”¨å®Œæ•´è®­ç»ƒæ¨¡å¼")
        
    elif choice == '4':
        # è‡ªå®šä¹‰å‚æ•°
        print("\nè‡ªå®šä¹‰è®­ç»ƒå‚æ•°:")
        epochs = input("è®­ç»ƒè½®æ•° [50]: ").strip() or '50'
        batch_size = input("èŠ‚ç‚¹æ‰¹å¤§å° [300]: ").strip() or '300'
        lr = input("å­¦ä¹ ç‡ [0.001]: ").strip() or '0.001'
        
        cmd = base_cmd + [
            '--epochs', epochs,
            '--node_batch_size', batch_size,
            '--learning_rate', lr,
            '--enable_vessel_aware',
            '--enable_visualization',
            '--save_training_curves'
        ]
        
        if has_large_gpu:
            use_large = input("å¯ç”¨å¤§æ¡ˆä¾‹è®­ç»ƒ? [y/N]: ").strip().lower()
            if use_large == 'y':
                cmd.extend(['--enable_large_cases', '--max_nodes_per_case', '8000'])
        
        print("ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰é…ç½®")
        
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return
    
    # æ˜¾ç¤ºå®Œæ•´å‘½ä»¤
    print(f"\nğŸ¯ æ‰§è¡Œå‘½ä»¤:")
    print(' '.join(cmd))
    
    # ç¡®è®¤å¼€å§‹è®­ç»ƒ
    print(f"\nğŸš€ å‡†å¤‡å¼€å§‹è®­ç»ƒ...")
    confirm = input("æŒ‰ Enter å¼€å§‹è®­ç»ƒï¼Œæˆ– Ctrl+C å–æ¶ˆ: ")
    
    try:
        # æ‰§è¡Œè®­ç»ƒå‘½ä»¤
        subprocess.run(cmd, check=True)
        print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•")

if __name__ == "__main__":
    main()
