#!/usr/bin/env python3
"""
TXTæ ¼å¼è®­ç»ƒæ—¥å¿—è®°å½•å™¨ - æ›¿ä»£TensorBoard
"""

import os
import time
from datetime import datetime
from pathlib import Path
import json

class TxtLogger:
    """TXTæ ¼å¼è®­ç»ƒæ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_dir, experiment_name="cpr_tagnet_training"):
        """
        åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        Args:
            log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
            experiment_name: å®éªŒåç§°
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å®éªŒç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_dir = self.log_dir / f"{experiment_name}_{timestamp}"
        self.experiment_dir.mkdir(exist_ok=True)
        
        # æ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.train_log_file = self.experiment_dir / "training_log.txt"
        self.metric_log_file = self.experiment_dir / "metrics.txt"
        self.config_file = self.experiment_dir / "config.json"
        
        # å†…å­˜ä¸­ä¿å­˜æŒ‡æ ‡æ•°æ®
        self.metrics = {
            'train_loss': [],
            'train_accuracy': [],
            'val_loss': [],
            'val_accuracy': [],
            'learning_rate': [],
            'epochs': []
        }
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        self._init_log_files()
        
        print(f"ğŸ“ TXTæ—¥å¿—åˆå§‹åŒ–å®Œæˆ")
        print(f"   å®éªŒç›®å½•: {self.experiment_dir}")
        print(f"   è®­ç»ƒæ—¥å¿—: {self.train_log_file.name}")
        print(f"   æŒ‡æ ‡æ—¥å¿—: {self.metric_log_file.name}")
    
    def _init_log_files(self):
        """åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶"""
        # è®­ç»ƒæ—¥å¿—æ–‡ä»¶å¤´
        with open(self.train_log_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("CPR-TaG-Net è®­ç»ƒæ—¥å¿—\n")
            f.write(f"å®éªŒå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 80 + "\n\n")
        
        # æŒ‡æ ‡æ—¥å¿—æ–‡ä»¶å¤´
        with open(self.metric_log_file, 'w', encoding='utf-8') as f:
            f.write("# CPR-TaG-Net è®­ç»ƒæŒ‡æ ‡è®°å½•\n")
            f.write("# æ ¼å¼: Epoch, Train_Loss, Train_Acc, Val_Loss, Val_Acc, Learning_Rate, Timestamp\n")
            f.write("Epoch\tTrain_Loss\tTrain_Acc\tVal_Loss\tVal_Acc\tLearning_Rate\tTimestamp\n")
    
    def log_message(self, message, level="INFO"):
        """è®°å½•æ–‡æœ¬æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}\n"
        
        # å†™å…¥è®­ç»ƒæ—¥å¿—
        with open(self.train_log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry)
        
        # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
        print(f"ğŸ“ {message}")
    
    def log_config(self, config_dict):
        """è®°å½•é…ç½®ä¿¡æ¯"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)
        
        self.log_message(f"é…ç½®ä¿¡æ¯å·²ä¿å­˜åˆ° {self.config_file.name}")
    
    def add_scalar(self, tag, value, step):
        """
        è®°å½•æ ‡é‡æŒ‡æ ‡ (å…¼å®¹TensorBoardæ¥å£)
        Args:
            tag: æŒ‡æ ‡æ ‡ç­¾ (å¦‚ 'Train/Loss', 'Val/Accuracy')
            value: æŒ‡æ ‡å€¼
            step: æ­¥æ•° (é€šå¸¸æ˜¯epoch)
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # è§£ææ ‡ç­¾
        if '/' in tag:
            category, metric = tag.split('/', 1)
        else:
            category, metric = 'General', tag
        
        # è®°å½•åˆ°å†…å­˜
        if tag == 'Train/EpochLoss':
            self.metrics['train_loss'].append((step, value))
        elif tag == 'Train/EpochAccuracy':
            self.metrics['train_accuracy'].append((step, value))
        elif tag == 'Val/EpochLoss':
            self.metrics['val_loss'].append((step, value))
        elif tag == 'Val/EpochAccuracy':
            self.metrics['val_accuracy'].append((step, value))
        elif 'LearningRate' in tag:
            self.metrics['learning_rate'].append((step, value))
        
        # è®°å½•åˆ°è®­ç»ƒæ—¥å¿—
        self.log_message(f"{category}/{metric}: {value:.6f} (Step: {step})")
    
    def log_epoch_summary(self, epoch, train_loss, train_acc, val_loss, val_acc, lr, extra_info=None):
        """è®°å½•æ¯ä¸ªepochçš„æ±‡æ€»ä¿¡æ¯"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # å†™å…¥æŒ‡æ ‡æ–‡ä»¶
        with open(self.metric_log_file, 'a', encoding='utf-8') as f:
            f.write(f"{epoch}\t{train_loss:.6f}\t{train_acc:.4f}\t{val_loss:.6f}\t{val_acc:.4f}\t{lr:.8f}\t{timestamp}\n")
        
        # å†™å…¥è®­ç»ƒæ—¥å¿—
        summary = f"""
{'='*60}
Epoch {epoch} è®­ç»ƒæ€»ç»“
{'='*60}
è®­ç»ƒæŸå¤±: {train_loss:.6f}
è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}%
éªŒè¯æŸå¤±: {val_loss:.6f}  
éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}%
å­¦ä¹ ç‡: {lr:.8f}
æ—¶é—´: {timestamp}
"""
        
        if extra_info:
            summary += f"é¢å¤–ä¿¡æ¯: {extra_info}\n"
        
        summary += "=" * 60 + "\n"
        
        with open(self.train_log_file, 'a', encoding='utf-8') as f:
            f.write(summary)
    
    def log_training_start(self, model_info, data_info, config_info):
        """è®°å½•è®­ç»ƒå¼€å§‹ä¿¡æ¯"""
        start_info = f"""
{'='*80}
è®­ç»ƒå¼€å§‹
{'='*80}

ğŸ¤– æ¨¡å‹ä¿¡æ¯:
{model_info}

ğŸ“Š æ•°æ®ä¿¡æ¯:
{data_info}

âš™ï¸ é…ç½®ä¿¡æ¯:
{config_info}

{'='*80}

"""
        with open(self.train_log_file, 'a', encoding='utf-8') as f:
            f.write(start_info)
    
    def log_training_end(self, best_epoch, best_acc, total_time):
        """è®°å½•è®­ç»ƒç»“æŸä¿¡æ¯"""
        end_info = f"""
{'='*80}
è®­ç»ƒç»“æŸ
{'='*80}
ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4f}% (Epoch {best_epoch})
â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f} åˆ†é’Ÿ
ğŸ“… ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“ æ—¥å¿—ç›®å½•: {self.experiment_dir}
{'='*80}
"""
        with open(self.train_log_file, 'a', encoding='utf-8') as f:
            f.write(end_info)
        
        # ç”Ÿæˆè®­ç»ƒæ€»ç»“æŠ¥å‘Š
        self._generate_summary_report(best_epoch, best_acc, total_time)
    
    def _generate_summary_report(self, best_epoch, best_acc, total_time):
        """ç”Ÿæˆè®­ç»ƒæ€»ç»“æŠ¥å‘Š"""
        summary_file = self.experiment_dir / "training_summary.txt"
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("CPR-TaG-Net è®­ç»ƒæ€»ç»“æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"ğŸ¯ æœ€ä½³ç»“æœ:\n")
            f.write(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4f}%\n")
            f.write(f"   æœ€ä½³Epoch: {best_epoch}\n")
            f.write(f"   æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f} åˆ†é’Ÿ\n\n")
            
            f.write(f"ğŸ“Š è®­ç»ƒç»Ÿè®¡:\n")
            if self.metrics['train_loss']:
                final_train_loss = self.metrics['train_loss'][-1][1]
                f.write(f"   æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.6f}\n")
            
            if self.metrics['train_accuracy']:
                final_train_acc = self.metrics['train_accuracy'][-1][1]
                f.write(f"   æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {final_train_acc:.4f}%\n")
                
            if self.metrics['val_loss']:
                final_val_loss = self.metrics['val_loss'][-1][1]
                f.write(f"   æœ€ç»ˆéªŒè¯æŸå¤±: {final_val_loss:.6f}\n")
                
            if self.metrics['val_accuracy']:
                final_val_acc = self.metrics['val_accuracy'][-1][1]
                f.write(f"   æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_val_acc:.4f}%\n")
            
            f.write(f"\nğŸ“ æ–‡ä»¶åˆ—è¡¨:\n")
            f.write(f"   è®­ç»ƒæ—¥å¿—: {self.train_log_file.name}\n")
            f.write(f"   æŒ‡æ ‡æ•°æ®: {self.metric_log_file.name}\n")
            f.write(f"   é…ç½®æ–‡ä»¶: {self.config_file.name}\n")
            f.write(f"   æ€»ç»“æŠ¥å‘Š: {summary_file.name}\n")
        
        print(f"ğŸ“‹ è®­ç»ƒæ€»ç»“æŠ¥å‘Šå·²ç”Ÿæˆ: {summary_file}")
    
    def close(self):
        """å…³é—­æ—¥å¿—è®°å½•å™¨"""
        self.log_message("æ—¥å¿—è®°å½•å™¨å…³é—­", "INFO")
        print(f"ğŸ“ æ—¥å¿—å·²ä¿å­˜åˆ°: {self.experiment_dir}")
    
    def get_experiment_dir(self):
        """è·å–å®éªŒç›®å½•è·¯å¾„"""
        return str(self.experiment_dir)

def create_txt_logger(log_dir, experiment_name="cpr_tagnet_training"):
    """åˆ›å»ºTXTæ—¥å¿—è®°å½•å™¨çš„å·¥å‚å‡½æ•°"""
    return TxtLogger(log_dir, experiment_name)

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•æ—¥å¿—è®°å½•å™¨
    logger = create_txt_logger("test_logs", "test_experiment")
    
    # æµ‹è¯•é…ç½®è®°å½•
    test_config = {
        "epochs": 25,
        "learning_rate": 0.0005,
        "batch_size": 300
    }
    logger.log_config(test_config)
    
    # æµ‹è¯•è®­ç»ƒå¼€å§‹
    logger.log_training_start(
        "CPR-TaG-Net (513Kå‚æ•°)",
        "18ç±»è¡€ç®¡ï¼Œ24ä¸ªæ¡ˆä¾‹",
        "25 epochs, lr=0.0005"
    )
    
    # æµ‹è¯•æŒ‡æ ‡è®°å½•
    for epoch in range(1, 4):
        train_loss = 2.5 - 0.1 * epoch
        train_acc = 40 + 5 * epoch
        val_loss = 2.8 - 0.08 * epoch
        val_acc = 35 + 6 * epoch
        lr = 0.0005
        
        logger.add_scalar('Train/EpochLoss', train_loss, epoch)
        logger.add_scalar('Train/EpochAccuracy', train_acc, epoch)
        logger.add_scalar('Val/EpochLoss', val_loss, epoch)
        logger.add_scalar('Val/EpochAccuracy', val_acc, epoch)
        
        logger.log_epoch_summary(epoch, train_loss, train_acc, val_loss, val_acc, lr)
    
    # æµ‹è¯•è®­ç»ƒç»“æŸ
    logger.log_training_end(best_epoch=3, best_acc=53.5, total_time=45.2)
    logger.close()
    
    print("âœ… TXTæ—¥å¿—è®°å½•å™¨æµ‹è¯•å®Œæˆ")
